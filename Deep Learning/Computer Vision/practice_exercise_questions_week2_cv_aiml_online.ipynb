{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGIsF1ADyJ58"
   },
   "source": [
    "# Transfer Learning CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-n6tVFayGBe"
   },
   "source": [
    "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgWNaP4SFZlP"
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq8ejXHJyGYq"
   },
   "source": [
    "### Import keras and CIFAR10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWYbxnBayFUP"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlh0c0dACZnA"
   },
   "source": [
    "### Get train and test data\n",
    "Use these variable names\n",
    "\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ap7iaMNG2Zbu"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3T-SswFTC4sL"
   },
   "source": [
    "### Print the shape of X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_AYES5F2eOt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-d2iEjeeDBM3"
   },
   "source": [
    "### Rehshape y_train and y_test\n",
    "reshape with y_train.shape[0] and y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIJRUpPO2gUy"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "y_test = y_test.reshape(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5_Q2VODDlhT"
   },
   "source": [
    "### Create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oWCfC9s2i-r"
   },
   "outputs": [],
   "source": [
    "X_train_lt_5 = X_train[y_train < 5]\n",
    "y_train_lt_5 = y_train[y_train < 5]\n",
    "X_test_lt_5 = X_test[y_test < 5]\n",
    "y_test_lt_5 = y_test[y_test < 5]\n",
    "\n",
    "X_train_gt_5 = X_train[y_train >= 5]\n",
    "y_train_gt_5 = y_train[y_train >= 5]\n",
    "X_test_gt_5 = X_test[y_test >= 5]\n",
    "y_test_gt_5 = y_test[y_test >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtCKmQh4yXhT"
   },
   "source": [
    "## Use One-hot encoding to divide y_train and y_test into required no of output classes\n",
    "Do it for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN5O2kJ3yYa6"
   },
   "outputs": [],
   "source": [
    "y_train_gt_5 = pd.get_dummies(y_train_gt_5)\n",
    "y_test_gt_5 = pd.get_dummies(y_test_gt_5)\n",
    "\n",
    "y_train_lt_5 = pd.get_dummies(y_train_lt_5)\n",
    "y_test_lt_5 = pd.get_dummies(y_test_lt_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5  6  7  8  9\n",
       "0      0  1  0  0  0\n",
       "1      0  0  0  0  1\n",
       "2      0  0  0  0  1\n",
       "3      0  0  1  0  0\n",
       "4      0  0  0  1  0\n",
       "5      0  0  1  0  0\n",
       "6      0  0  1  0  0\n",
       "7      0  0  0  0  1\n",
       "8      0  0  0  0  1\n",
       "9      0  0  0  0  1\n",
       "10     0  1  0  0  0\n",
       "11     0  1  0  0  0\n",
       "12     0  1  0  0  0\n",
       "13     0  1  0  0  0\n",
       "14     1  0  0  0  0\n",
       "15     0  0  0  0  1\n",
       "16     0  0  1  0  0\n",
       "17     1  0  0  0  0\n",
       "18     0  0  1  0  0\n",
       "19     0  0  0  0  1\n",
       "20     1  0  0  0  0\n",
       "21     0  0  1  0  0\n",
       "22     0  0  0  0  1\n",
       "23     1  0  0  0  0\n",
       "24     0  0  0  1  0\n",
       "25     0  0  0  0  1\n",
       "26     0  0  1  0  0\n",
       "27     0  0  0  1  0\n",
       "28     1  0  0  0  0\n",
       "29     0  0  0  0  1\n",
       "...   .. .. .. .. ..\n",
       "24970  0  0  0  1  0\n",
       "24971  1  0  0  0  0\n",
       "24972  0  0  1  0  0\n",
       "24973  0  0  1  0  0\n",
       "24974  0  0  1  0  0\n",
       "24975  0  0  0  0  1\n",
       "24976  0  1  0  0  0\n",
       "24977  0  1  0  0  0\n",
       "24978  0  1  0  0  0\n",
       "24979  0  0  0  1  0\n",
       "24980  0  0  0  1  0\n",
       "24981  1  0  0  0  0\n",
       "24982  0  0  0  1  0\n",
       "24983  0  0  1  0  0\n",
       "24984  0  1  0  0  0\n",
       "24985  0  0  0  0  1\n",
       "24986  1  0  0  0  0\n",
       "24987  0  0  1  0  0\n",
       "24988  0  1  0  0  0\n",
       "24989  0  0  0  1  0\n",
       "24990  0  0  0  1  0\n",
       "24991  0  0  0  0  1\n",
       "24992  0  0  0  1  0\n",
       "24993  0  0  1  0  0\n",
       "24994  1  0  0  0  0\n",
       "24995  0  0  0  1  0\n",
       "24996  0  0  1  0  0\n",
       "24997  1  0  0  0  0\n",
       "24998  0  1  0  0  0\n",
       "24999  0  0  0  0  1\n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_gt_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-6agMpZD9E_"
   },
   "source": [
    "### Print data variables for dataset having classes from 0 to 4\n",
    "Data variables here are referring to X-train, X_test, y_train, y_test of that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8Sm5YzM2orX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_gt_5.shape)\n",
    "display(X_train_lt_5.shape)\n",
    "display(y_train_gt_5.shape)\n",
    "display(y_train_lt_5.shape)\n",
    "\n",
    "display(X_test_gt_5.shape)\n",
    "display(X_test_lt_5.shape)\n",
    "display(y_test_gt_5.shape)\n",
    "display(y_test_lt_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x138070ef0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(2,2))\n",
    "img = X_train[5]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buY4EplOEaLN"
   },
   "source": [
    "### Print data variables for dataset having classes from 5 to 9\n",
    "Data variables here are referring to X-train, X_test, y_train, y_test of that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfnfqV2B2qmW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuOiKWfeybAl"
   },
   "source": [
    "## Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7JwiBbcE2dL"
   },
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HzxNbiiyoBD"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, MaxPooling2D, Conv2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2rue0r3E9YK"
   },
   "source": [
    "### Initialize a model and add the required layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HucP-Qg2ufi"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3), name='conv_1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='pool_1'))\n",
    "model.add(Dropout(0.2,name='drop_1'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3), name='conv_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, name='pool_2'))\n",
    "model.add(Dropout(0.2, name='drop_2'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu', name='dense_1'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax', name='dense_3'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SUCOn4SFE_H"
   },
   "source": [
    "### Summarize your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGHKqBkZ2wZn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "drop_1 (Dropout)             (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "drop_2 (Dropout)             (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               276600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 605       \n",
      "=================================================================\n",
      "Total params: 296,597\n",
      "Trainable params: 296,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ByO-o9JFJCq"
   },
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBgb4RDk21q3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 2.4029 - accuracy: 0.4348 - val_loss: 1.0425 - val_accuracy: 0.5836\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 1.0198 - accuracy: 0.5855 - val_loss: 0.8877 - val_accuracy: 0.6470\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.9303 - accuracy: 0.6300 - val_loss: 0.9009 - val_accuracy: 0.6636\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.8512 - accuracy: 0.6703 - val_loss: 0.8542 - val_accuracy: 0.6760\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.7888 - accuracy: 0.6970 - val_loss: 0.8295 - val_accuracy: 0.6770\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.7433 - accuracy: 0.7156 - val_loss: 0.7428 - val_accuracy: 0.7198\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.6990 - accuracy: 0.7348 - val_loss: 0.7135 - val_accuracy: 0.7312\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.6611 - accuracy: 0.7488 - val_loss: 0.6968 - val_accuracy: 0.7404\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.6275 - accuracy: 0.7638 - val_loss: 0.6915 - val_accuracy: 0.7426\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.5960 - accuracy: 0.7762 - val_loss: 0.7043 - val_accuracy: 0.7446\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.5726 - accuracy: 0.7848 - val_loss: 0.7312 - val_accuracy: 0.7338\n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.5503 - accuracy: 0.7940 - val_loss: 0.6943 - val_accuracy: 0.7542\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.5234 - accuracy: 0.8070 - val_loss: 0.6816 - val_accuracy: 0.7574\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.5021 - accuracy: 0.8148 - val_loss: 0.7189 - val_accuracy: 0.7488\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4981 - accuracy: 0.8140 - val_loss: 0.6854 - val_accuracy: 0.7518\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4766 - accuracy: 0.8262 - val_loss: 0.7256 - val_accuracy: 0.7416\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.4559 - accuracy: 0.8328 - val_loss: 0.6839 - val_accuracy: 0.7600\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4520 - accuracy: 0.8323 - val_loss: 0.7001 - val_accuracy: 0.7624\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4229 - accuracy: 0.8484 - val_loss: 0.7373 - val_accuracy: 0.7570\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4043 - accuracy: 0.8542 - val_loss: 0.7203 - val_accuracy: 0.7596\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4144 - accuracy: 0.8484 - val_loss: 0.7576 - val_accuracy: 0.7514\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3813 - accuracy: 0.8628 - val_loss: 0.7493 - val_accuracy: 0.7648\n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3705 - accuracy: 0.8660 - val_loss: 0.7578 - val_accuracy: 0.7674\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3528 - accuracy: 0.8711 - val_loss: 0.7682 - val_accuracy: 0.7568\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3708 - accuracy: 0.8651 - val_loss: 0.7403 - val_accuracy: 0.7644\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.3605 - accuracy: 0.8712 - val_loss: 0.7496 - val_accuracy: 0.7628\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.3575 - accuracy: 0.8736 - val_loss: 0.7668 - val_accuracy: 0.7678\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.3379 - accuracy: 0.8804 - val_loss: 0.7927 - val_accuracy: 0.7688\n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3280 - accuracy: 0.8840 - val_loss: 0.8144 - val_accuracy: 0.7576\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.3263 - accuracy: 0.8862 - val_loss: 0.8215 - val_accuracy: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1392dccf8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_lt_5, y_train_lt_5, validation_data=(X_test_lt_5,y_test_lt_5),\n",
    "         epochs=30, batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4wvh-JCFNWB"
   },
   "source": [
    "### Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIpZqrtF24fO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 243us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8215060812950135, 0.7649999856948853]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_lt_5, y_test_lt_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woTfNst_ynRG"
   },
   "source": [
    "## In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWpSpxEg2zHC"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if('dense' not in layer.name):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbOAuPQaF00B"
   },
   "source": [
    "### Print in colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_VCDB3Byb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mconv_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mpool_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdrop_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mconv_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mpool_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdrop_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mflatten_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_1\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mdense_3\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-uUPqWpyeyX"
   },
   "source": [
    "## Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
    "Achieve an accuracy of more than 85% on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szHjJgDvyfCt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 10s 415us/step - loss: 0.9762 - accuracy: 0.6616 - val_loss: 0.6721 - val_accuracy: 0.7540\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 11s 430us/step - loss: 0.6380 - accuracy: 0.7723 - val_loss: 0.5908 - val_accuracy: 0.7926\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 10s 405us/step - loss: 0.5572 - accuracy: 0.8039 - val_loss: 0.5551 - val_accuracy: 0.8064\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 10s 416us/step - loss: 0.5122 - accuracy: 0.8179 - val_loss: 0.5363 - val_accuracy: 0.8110\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 10s 414us/step - loss: 0.4762 - accuracy: 0.8304 - val_loss: 0.5344 - val_accuracy: 0.8090\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 11s 421us/step - loss: 0.4509 - accuracy: 0.8397 - val_loss: 0.5298 - val_accuracy: 0.8150\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 11s 423us/step - loss: 0.4283 - accuracy: 0.8471 - val_loss: 0.5285 - val_accuracy: 0.8232\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 11s 420us/step - loss: 0.4033 - accuracy: 0.8580 - val_loss: 0.5263 - val_accuracy: 0.8184\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 12s 464us/step - loss: 0.3907 - accuracy: 0.8590 - val_loss: 0.5396 - val_accuracy: 0.8180\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 11s 444us/step - loss: 0.3770 - accuracy: 0.8639 - val_loss: 0.5453 - val_accuracy: 0.8188\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 11s 455us/step - loss: 0.3604 - accuracy: 0.8706 - val_loss: 0.5319 - val_accuracy: 0.8230\n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 11s 447us/step - loss: 0.3507 - accuracy: 0.8734 - val_loss: 0.5434 - val_accuracy: 0.8194\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 12s 467us/step - loss: 0.3367 - accuracy: 0.8800 - val_loss: 0.5411 - val_accuracy: 0.8208\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 13s 510us/step - loss: 0.3255 - accuracy: 0.8835 - val_loss: 0.5533 - val_accuracy: 0.8218\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 0.3136 - accuracy: 0.8891 - val_loss: 0.5604 - val_accuracy: 0.8084\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 12s 486us/step - loss: 0.3105 - accuracy: 0.8894 - val_loss: 0.5608 - val_accuracy: 0.8238\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 12s 461us/step - loss: 0.3043 - accuracy: 0.8918 - val_loss: 0.5592 - val_accuracy: 0.8248\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 11s 442us/step - loss: 0.2951 - accuracy: 0.8968 - val_loss: 0.5777 - val_accuracy: 0.8218\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 12s 474us/step - loss: 0.2887 - accuracy: 0.8978 - val_loss: 0.5671 - val_accuracy: 0.8274\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 11s 444us/step - loss: 0.2785 - accuracy: 0.9015 - val_loss: 0.6008 - val_accuracy: 0.8198\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 11s 449us/step - loss: 0.2751 - accuracy: 0.9026 - val_loss: 0.5953 - val_accuracy: 0.8238\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 11s 460us/step - loss: 0.2673 - accuracy: 0.9058 - val_loss: 0.5878 - val_accuracy: 0.8246\n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 12s 478us/step - loss: 0.2588 - accuracy: 0.9100 - val_loss: 0.5891 - val_accuracy: 0.8206\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 11s 460us/step - loss: 0.2575 - accuracy: 0.9096 - val_loss: 0.6025 - val_accuracy: 0.8188\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 12s 461us/step - loss: 0.2553 - accuracy: 0.9107 - val_loss: 0.5962 - val_accuracy: 0.8268\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 12s 463us/step - loss: 0.2450 - accuracy: 0.9147 - val_loss: 0.6092 - val_accuracy: 0.8276\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 12s 466us/step - loss: 0.2354 - accuracy: 0.9179 - val_loss: 0.6202 - val_accuracy: 0.8202\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 12s 462us/step - loss: 0.2358 - accuracy: 0.9183 - val_loss: 0.6187 - val_accuracy: 0.8216\n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 12s 464us/step - loss: 0.2336 - accuracy: 0.9187 - val_loss: 0.6062 - val_accuracy: 0.8188\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 12s 464us/step - loss: 0.2254 - accuracy: 0.9210 - val_loss: 0.6582 - val_accuracy: 0.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x138095710>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "model.fit(X_train_gt_5, y_train_gt_5, validation_data=(X_test_gt_5,y_test_gt_5),\n",
    "         epochs=30, batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_Hd90rP4L1n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "practice_exercise_questions_week2_cv_aiml_online",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

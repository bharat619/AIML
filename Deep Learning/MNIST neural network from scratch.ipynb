{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectifier Linear Activation Layer (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_features = train_features.reshape(60000, 784)\n",
    "print(train_features.shape)\n",
    "test_features = test_features.reshape(10000, 784)\n",
    "print(test_features.shape)\n",
    "\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_targets\n",
    "\n",
    "X_val = test_features\n",
    "y_val = test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATuklEQVR4nO2deZiN5RvHPzOMogxZmpmI0DAKaeyaa4iIFkSUIjspW4sS+iFbwnTZIksUXcnVQiiSEaFctLjsWdvQlExZosH5/XGu+3nPzJzZz3vOe477888wZ3ueed/zvs/zvb/3fYe5XC4URVEURVFCmfBAD0BRFEVRFMVudMGjKIqiKErIowseRVEURVFCHl3wKIqiKIoS8uiCR1EURVGUkEcXPIqiKIqihDyFs3swLCwsqHPWXS5XWE7P0Tk6n5zmGOrzA51jMKBzDP35gc4xGMhqjqrwKIqiKIoS8uiCR1EURVGUkEcXPIqiKIqihDy64FEURVEUJeTRBY+iKIqiKCGPLnj8RJ06dVi4cCELFy7k8uXLXL582fw/Pj4+0MNTFCVImTZtGi6XC5fLxa5du9i1axcVK1YM9LAUxeesX7+e5ORkkpOT8/V6XfAoiqIoihLyZFuHxw4KFSpEiRIlMv1+wIABABQrVgyAatWqAfD0008zZcoUADp37gzAhQsXePXVVwEYM2aM7WMuCLVr1wZg3bp1REZGAuByuUscdO3aFYA2bdpQunTpwAzQjzRv3hyAd999F4AmTZpw4MCBQA6pwIwcORJwn4fh4e79Q9OmTQHYuHFjoIalZEPx4sW5/vrrAbj//vsBKFu2LABJSUlcvHgxYGPLC7fccgsAXbp04cqVKwBUr14dgLi4OH766adADc0nVK1aFYCIiAgSExMBeOONNwDMfLNixYoVADz66KMA/Pfff3YN0ydERETQuHFjACZMmADAXXfdFcghOYrXX38dgMaNG/POO+/k+31sWfBUqFCBIkWKAJiDmJCQAEDJkiXp0KFDju/x66+/AjB9+nQeeughAM6cOQPAzp07HX8zqV+/PgAffvghACVKlDALHZmHfAlLly5Nw4YNAfjuu+/SPWY3ciEpXbo0H3/8sa2fVa9ePQC2b99u6+f4g+7duwPw4osvAukvwHKcFWcgCwM5Vo0aNaJGjRpenxsTE8OgQYP8NbQC8ccffwCwadMm2rRpE+DRFJzbb78dsL5bHTt2BCA8PJybbroJsL5nOX3H5O8xZ84cAIYMGcI///zj8zH7ihIlSrBhwwYATp48CUB0dLT599WKCBtPPvkkAGlpaaxfvz7f76chLUVRFEVRQh6fKjwSvklOTvYatsoNsoKXUMHZs2dNCOTEiRMAnD592pGhEAnHxcfHs2TJEsC9Y8zIwYMHAXjttdcAWLp0KVu2bAGseU+cONH28YIVfomNjbVV4QkPD6dSpUoAxlAZFpZjhXPHInO49tprAzyS/NOgQQO6dOkCuMOLYO2yAZ5//nkAjh8/DrhVWjmvt23b5s+h5pm4uDjAvbN//PHHAShatCjgPu9++eUXwFJbJRTUqVMnEzbZv3+/X8ecV86dOwcQ9KErQa559913n8/e84knngBgwYIF5hrrdKKjo83Pq13hkchHREQEAJs3b2bZsmX5fj9VeBRFURRFCXl8qvD8/PPPAJw6dSpXCo/sElNTU7n77rsBy7uyePFiXw7NL7z55puAZa7OCklDF+Pkxo0bjdJSq1Yt+wboBdkBff3117Z+TkxMDH369AEwKoHTd9DeuOeeewAYOHBgut/v37+fBx54AIDff//d7+PKC4888gjgTmcuU6YMYKltX375pTHwTp48Od3rwsLCzGNiBnUKcr2ZNGkSYM2xePHimZ578OBB7r33XsDaOcq5WKZMGfM3cTolS5YE4I477gjwSHzDunXrgMwKT0pKCgsWLAAwiQGenjnxiYpKGewEs/KdHYmJiYwYMQKw7pF//fVXls/v3Lmz8dodPnwYsFTn/OLTBY8MfujQoebi//333wNu87Hwww8/ANCiRQvALc2KlD548GBfDskv1KlTB7AyPjxPWDFXr1y50mSbSYhA/janT5+mWbNmmV7rD+QCYjfz5883/5aQXrCRkJDAwoULATIt6CdPnuzY0ELhwu6ved26dQGYN28e4A7Bbtq0CYCxY8cCbsn4mmuuATDSccuWLc177dixwz+DziOS2NC7d+8snyMXzRYtWpiQ1q233mr/4GxCQugVKlTI9Fi9evXMIs6p52VGZs+eDcDy5cvT/T4tLS3b0I5kv+7evRvAGJw938up5603xJAdzOFyb8ydO5fY2FgAbrvtNsB9vcmK4cOHm+xl2Szv3LmzQGPQkJaiKIqiKCGPLWnpy5cvN5UQxRQosmuvXr2M0iGmO4A9e/YA0LdvXzuGZAueNXaAdHV2PvvsM8CS7po0aWIMyaJ2SFrpzp07jUQrKlF8fLxJUbcDCZ1FRUXZ9hmeeCoi8vcKNrp165Zu9wjuEBBQoNoQdiPGZE+VDdzHQUI/nim78jtPZQfcpSLefvttO4eabySFOSPHjh0zZRAkLV3UHbDMysGIKMWLFi1i9OjR6R4bPXo0qampAMycOdPfQ8sXly5dAtIfn9wg4ckbbrgh02NS3iRYait5UrduXb755ptAD8NnnD9/PlfqldxXK1asaO6LvlK7VOFRFEVRFCXksa3ScsYiT3///bf5t8Tj3n//fSDnqplOpGrVqgwdOhSw1Is///wTcKfPy0747NmzAKxevZrVq1fn+L6SOvvcc8+ZdFo7EGOgfJ5diIIkKekAv/32m62f6WvExNqzZ09zrsruedy4cQEbV24YO3Ysw4cPByxvgKRdjxw50msxNjEWZmTQoEFGlXQack0Rhfjzzz8H4NChQ6SkpGT5On8pnHYyduzYTArP1YAY5+XYe7uW/e9///PrmPLLpUuXzD1S7idVqlQJ5JB8hvgDa9asyb59+wDvXpzrrrsOsJTYYsWKGYXrgw8+8MlYVOFRFEVRFCXk8VsvLdmB1KlTx6QPSoqv7MaCAclgmTJlilFJxKckKd47duwosHLiLfPCl0ivMkE8VL5G/FpRUVH8+OOPgPX3cjrSkkDag3gyY8YMAFMO3mnIznb48OGm1MPatWsBawf177//mudLjLxly5bm3JOMQVGxpD+RExE/S16VjkaNGtkwGv/jLV07FBHVe9iwYSbDTkoLeCKZwGlpaf4bXAFITU3lq6++AjAZzsHOzTffDFgK3KVLl0zPTG9KcVJSEmD58Y4fP+7zfmJ+W/CIQblPnz7GjCvpsRs2bDBpg7NmzQKc24/ozjvvBNLXimjbti0Q3M0ifdHfKjIyklatWgGWUdbT+CrSpoSDnI7MxbM2kvRxmTZtWkDGlBNSm+Wpp54C3N8jWei0a9cu0/PlpiHVzKXEAlgyslQED1akN5ZI5p7UrFkz3f+3bt1qe00qO8htjyknIxsMaaosG2JPpCejt3lKeHbYsGF8+umnQPpFveIfpHaOVO4XS8CMGTO83iOlto70UBPGjx/v87FpSEtRFEVRlJDHbwqPcPjwYbOSkyJuXbt2Nat62YVJmq/0z3IKIruFhYWZ1aovlJ1AS9KlSpXy+nspJyDhDdl1lS9fniJFigCWzBweHm52VFJFW9JBCxcuzLfffmvT6H1Pu3btTKdeYfPmzXTr1g1Ib8J3EnJMPKsFi8Jx4403AtCjRw/A3VFadmNS9dvlcpnds1TE9iwf4XSkGJ8UNhs1alSmyr3h4eGZvmcSEuvRoweXL1/2w0gVT2rUqMEnn3wC5D+cLyGhuXPn+mxcgUSK7gUDUty0S5cuWVbFbtSoES+99BJg3UdLlSplQlhyj5F7v3Qu8CWq8CiKoiiKEvL4XeEBK7YnLQaSkpJo3rw5ABMmTACsbtTjx493RBqzGMmkKJLL5TI7El+QMQYvpju7ECVGPm/OnDkmfdkT8a/I6luKg50/f569e/cC8NZbbwFus7aoXdJPSgp/FS1aNCh6Z2VnVD5y5Ijj+2SJQVlMgWXLluXo0aOAd9+DKBvif4iJiTHlFVauXGn7eH1BRESE8dbJcYuJiQHc57nMUbw5rVq1MkqQIDvU9u3bG3+W/C0V/yDXmOza62SnhMs1unXr1qbwazDTpk2bQA8h10iJgPnz55vrjByjQ4cOAe5CitLeRnyv5cqVM99VuWb17NnTtnEGZMEjSO+TTp068eCDDwJWmKtfv34AxMbGmp5bgUSyriRkkJKSYuoI5RfJ+PLMLJEK1SL92YWYWqXPjjTgy4g0hJWeNFJHIacKoFIPRZpNHjlypIAj9g+SweTtgpoxxOVExBAuBuVVq1aZcKX0kpJsq0WLFpn+d0uXLgXcCwX5t9OR72KrVq346KOP0j02ZswYwP192rJlC2CFbZOTk00oT5DzdOLEiZnO+WCo0uttIZCYmAgER6Xl3bt3mwbKkvAgZvsLFy54fU2vXr2AzI18gxXJ+AymLC2pyi737bS0NHMNeuyxxwB3r0iAqVOnmgxtWfiEhYWZBZKE4aXSdtOmTc01y1doSEtRFEVRlJAnoAqPkJqayuLFiwGr349IzImJiWblL32LnMDFixfzbagWZUd6aw0dOtSEfqZOnQpYFZrtZtKkSba8r4QoBW8hIichocqM/aPAUkQOHDjg1zEVBDGNi3KRFaICyM7rypUrjlfjpO6KqDhS8RwwoQypk5Sammr+BpKqXLNmTROukpR7UXzatm1rUvS/+OILwP0dkV2qYHfIOa94S0tv3749YBm4JQTtVERtzm06sijjoaLwiLIoREREGGuHUzveSyRGxj5u3Dij9mRk4MCBxojsrf6VhDJF6fK1ugOq8CiKoiiKchUQUIVHDLEPP/ww9erVcw+ocPoh7d27l02bNvl9bDmRH8OyqAiyI5X454oVK+jQoYPvBudAxKjuVKTat2fHZfEpZSyIFUqIN81TIXCyh6dQoUKmgKUULDt37hzDhg0DLC+S+Ajq1q1rPCxibD548CD9+/cHrN1kZGQk4PaySZkFMY2uW7fOfL74Czx7wzmBOXPmANaO2xPx0w0ZMsSvY7Ib6ZIeKkhCiBAWFmaiAU5F1G/x0GXX6b5MmTKZvHOdO3c2Xl5Boh12oAqPoiiKoighj98VnmrVqpl+GhJjjo6OzvQ8Kf514sQJR/SHyZgy2a5dOwYPHpzr1z/zzDO8/PLLgNUNV7wC0oNLCRxS5MvzXJOu4v7yUwUCyYQJFvr27WuUnfPnzwNuVUMUuoYNGwJWccXWrVsbFeuVV14B3BklGXeikpa/Zs0a1qxZA7h3n2Blm4D7e+xEgqHkgyfiwxLPXHJycp7aQPTo0cOx7V3yi6glcizj4uKMKidZtU4jN8dA7ncdO3Y0Sqr4c5YtW2bf4Lxg+4JHFjNy8RgwYICpdeIN6aklxjVf1ropCGIGlJ/R0dFMnz4dsOrQnDp1CnBfdKVytFQqLl++vDF2yU1GbqihjCwQq1atmmMqeyAQg52k9XqydetWfw/H7wRbWECaooI7vAXuELEYWKU3mCfy2MSJEwFyXUn5vffeS/fTyYhJWwy8VapUMY/JxkyeY4cZNC8kJCQwYsQIAFNypFKlStmGQ6SkgFTNTkpKylRLSRZMWaWxBwuyeC9XrhzPPvtsgEdTcGSx1r9/f1JSUgBo1qxZQMaiIS1FURRFUUIeWxSeqKgokwophsG4uLgsn79t2zYmT54MWLKeE8JY2VGoUCGzchXDscjisbGxmZ6/detWY5D03KWGOqKIeVNQAk3t2rVNbzA53yRdedasWY6vquwLKleuHOgh5ImTJ0+aNHMxdIqKClbquSQ6LF++nGPHjgG5V3aCmT179gDpj6vTrqUzZ87MZF594YUXOHPmTJavESUoPj4eSJ9+L+VKZs+eDVhG9GDH5XIFdbVvSanv3bs34J6P9Dmz05icHc67CymKoiiKovgYnyg8El+VokK1a9fOduco3ggpsrd27do8GdYCgfTh2b59O4BJowfLpxQVFWV+J34eSZPNi8E5FGnUqBGLFi0K9DDSUbJkyUyGeenbJsbYUEc6TGfXo8hJJCYmmrYZsttPSUkxPjopEBjMO+OCIDtoadUTLEiZgNySkpJier3JtTXYvTsZiYyMND2nnF7WwxtSzkGUniVLljBq1KhADin/C54GDRoAbsNg/fr1AbfJKisko2L69OmmQei5c+fy+/F+RyQ4ySzr16+fqZSckWnTphl5VRqnXa1k1whQCTxSA0Ma+VauXNkYXqWZn5M4c+aMqcouPxULqaa8b98+qlevHuDReKd79+7GXN2tW7ccn3/48GFz/5AF+ty5czPVbwkVOnXqBLir+UvvwmBEEkKkbpbYVQKJhrQURVEURQl5wjzNX5keDAvL8kHpHO3Zx0bYu3cvq1atAqzqkRK+kgqo/sDlcuUoL2Q3x2DAqXOU6sQSapg3b57XKrC5Iac55nd+0dHRpuN9QkICAEePHgW8pzfbhROOoRyv+fPns3HjRsBKcfZFDyYnzNFudI65n58YzuW8GzdunKlyLl3qJSSyYsUKTp48mb8B5xEnHEOxQVSvXt1U+/ZlLy0nzNFuspqjKjyKoiiKooQ8+VZ4goGreSXrSajPMdTnB/bPUSqgLlu2zKTqS38cqVpcEM+dE+ZoNzrH0J8f6ByDAVV4FEVRFEW5alGFR+foeHRX6b85RkZGmrYukipcq1YtoGBeHifN0S50jqE/P9A5BgNZzVEXPDpHx6MXWZ1jMKBzDP35gc4xGNCQlqIoiqIoVy3ZKjyKoiiKoiihgCo8iqIoiqKEPLrgURRFURQl5NEFj6IoiqIoIY8ueBRFURRFCXl0waMoiqIoSsijCx5FURRFUUKe/wPGPTVWnzoaPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28,28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy(), mode='train'):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return p\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining update function (SGD with momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] - learning_rate * g[i]\n",
    "            p[i] += v[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.48755990068218685 | Training Accuracy = 0.9381166666666667 | Val Loss = 0.11966338232166268 | Val Accuracy = 0.9366\n",
      "Loss = 0.18089931460377315 | Training Accuracy = 0.957 | Val Loss = 0.07707189167589312 | Val Accuracy = 0.9541\n",
      "Loss = 0.13418472286757374 | Training Accuracy = 0.96835 | Val Loss = 0.042494696043868636 | Val Accuracy = 0.962\n",
      "Loss = 0.11078063627641484 | Training Accuracy = 0.9707 | Val Loss = 0.033607762649984725 | Val Accuracy = 0.9623\n",
      "Loss = 0.09682899014460995 | Training Accuracy = 0.9706833333333333 | Val Loss = 0.03044574716599489 | Val Accuracy = 0.9604\n",
      "Loss = 0.0868328547827688 | Training Accuracy = 0.9715833333333334 | Val Loss = 0.026621312537132038 | Val Accuracy = 0.9615\n",
      "Loss = 0.07922587564463619 | Training Accuracy = 0.9721833333333333 | Val Loss = 0.026927097368782803 | Val Accuracy = 0.9604\n",
      "Loss = 0.07435006835457149 | Training Accuracy = 0.97395 | Val Loss = 0.02895926809115212 | Val Accuracy = 0.9597\n",
      "Loss = 0.07014696397167437 | Training Accuracy = 0.9753833333333334 | Val Loss = 0.027417569063357797 | Val Accuracy = 0.9629\n",
      "Loss = 0.06594762410408485 | Training Accuracy = 0.97625 | Val Loss = 0.02843717358522115 | Val Accuracy = 0.9627\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train, y_train, minibatch_size=200, epoch = 10, learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x154ca9b70>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[4].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = nn.predict_scores(X_val[4])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.21607772e-08, 8.96688318e-05, 1.81752135e-06, 1.06435534e-07,\n",
       "       9.97906089e-01, 4.08327788e-08, 6.55437243e-07, 1.34608780e-04,\n",
       "       6.94180536e-09, 1.86692389e-03])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
